{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a72f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (run once in the notebook if packages missing)\n",
    "# !pip install scikit-learn pandas numpy\n",
    "\n",
    "# Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebd604",
   "metadata": {},
   "source": [
    "# Build synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f53f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chunk</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Education background</td>\n",
       "      <td>Office location and parking instructions.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education background</td>\n",
       "      <td>Advertising copy and marketing slogans.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning experience</td>\n",
       "      <td>He has 5 years of ML experience, worked on cla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DevOps experience</td>\n",
       "      <td>He has 5 years of ML experience, worked on cla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DevOps experience</td>\n",
       "      <td>Automated testing and deployment for ML services.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Work experience</td>\n",
       "      <td>MSc in AI with focus on probabilistic models.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cloud experience</td>\n",
       "      <td>Managed infra via Terraform and monitored with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python libraries</td>\n",
       "      <td>Uses numpy, pandas, scikit-learn, and matplotl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0         Education background   \n",
       "1         Education background   \n",
       "2  Machine learning experience   \n",
       "3            DevOps experience   \n",
       "4            DevOps experience   \n",
       "5              Work experience   \n",
       "6             Cloud experience   \n",
       "7             Python libraries   \n",
       "\n",
       "                                               chunk  label  \n",
       "0          Office location and parking instructions.      0  \n",
       "1            Advertising copy and marketing slogans.      0  \n",
       "2  He has 5 years of ML experience, worked on cla...      1  \n",
       "3  He has 5 years of ML experience, worked on cla...      0  \n",
       "4  Automated testing and deployment for ML services.      1  \n",
       "5      MSc in AI with focus on probabilistic models.      0  \n",
       "6  Managed infra via Terraform and monitored with...      1  \n",
       "7  Uses numpy, pandas, scikit-learn, and matplotl...      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create templates for questions and positive chunks (personal/resume-style)\n",
    "questions = [\n",
    "    \"Machine learning experience\",\n",
    "    \"Python libraries\",\n",
    "    \"Education background\",\n",
    "    \"Work experience\",\n",
    "    \"Projects completed\",\n",
    "    \"Research interests\",\n",
    "    \"Data engineering skills\",\n",
    "    \"Cloud experience\",\n",
    "    \"DevOps experience\",\n",
    "    \"Publication list\"\n",
    "]\n",
    "\n",
    "positive_templates = {\n",
    "    \"Machine learning experience\": [\n",
    "        \"He has 5 years of ML experience, worked on classification and regression.\",\n",
    "        \"Worked with training pipelines, hyperparameter tuning and model evaluation.\"\n",
    "    ],\n",
    "    \"Python libraries\": [\n",
    "        \"Uses numpy, pandas, scikit-learn, and matplotlib regularly.\",\n",
    "        \"Familiar with PyTorch and TensorFlow for model building.\"\n",
    "    ],\n",
    "    \"Education background\": [\n",
    "        \"Completed BSc in Computer Science from XYZ University, graduated 2020.\",\n",
    "        \"MSc in AI with focus on probabilistic models.\"\n",
    "    ],\n",
    "    \"Work experience\": [\n",
    "        \"Worked as ML Engineer at Acme Corp from 2021 to 2024.\",\n",
    "        \"Interned at Data Labs building ETL pipelines and dashboards.\"\n",
    "    ],\n",
    "    \"Projects completed\": [\n",
    "        \"Built an end-to-end RAG chatbot for enterprise FAQs.\",\n",
    "        \"Deployed a recommendation system using collaborative filtering.\"\n",
    "    ],\n",
    "    \"Research interests\": [\n",
    "        \"Interested in representation learning and retrieval methods.\",\n",
    "        \"Exploring contrastive learning for domain adaptation.\"\n",
    "    ],\n",
    "    \"Data engineering skills\": [\n",
    "        \"Experience with Airflow, Spark, and data lake architectures.\",\n",
    "        \"Built ETL pipelines using Python and SQL for high-throughput data.\"\n",
    "    ],\n",
    "    \"Cloud experience\": [\n",
    "        \"Deployed microservices on AWS and GCP, used serverless functions.\",\n",
    "        \"Managed infra via Terraform and monitored with Prometheus.\"\n",
    "    ],\n",
    "    \"DevOps experience\": [\n",
    "        \"CI/CD pipelines using GitHub Actions and Docker containers.\",\n",
    "        \"Automated testing and deployment for ML services.\"\n",
    "    ],\n",
    "    \"Publication list\": [\n",
    "        \"Co-authored a workshop paper on RAG at a regional conference.\",\n",
    "        \"Published blog posts on ML interpretability and retrieval.\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generic negative chunks (irrelevant)\n",
    "negative_snippets = [\n",
    "    \"Company cafeteria menu and working hours details.\",\n",
    "    \"Office location and parking instructions.\",\n",
    "    \"Holiday policy and internal social events.\",\n",
    "    \"Financial statements and investor relations notes.\",\n",
    "    \"Advertising copy and marketing slogans.\"\n",
    "]\n",
    "\n",
    "# Build dataset: 100 records, balanced positives and negatives across questions\n",
    "records = []\n",
    "num_samples = 100\n",
    "for i in range(num_samples):\n",
    "    q = random.choice(questions)\n",
    "    # half positives, half negatives approximately\n",
    "    label = 1 if i % 2 == 0 else 0\n",
    "    if label == 1:\n",
    "        chunk = random.choice(positive_templates[q])\n",
    "    else:\n",
    "        # pick a negative snippet or a positive from a different question to make a hard negative\n",
    "        if random.random() < 0.6:\n",
    "            chunk = random.choice(negative_snippets)\n",
    "        else:\n",
    "            # hard negative: positive text for a different question\n",
    "            other_q = random.choice([qq for qq in questions if qq != q])\n",
    "            chunk = random.choice(positive_templates[other_q])\n",
    "    records.append({\"question\": q, \"chunk\": chunk, \"label\": label})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle\n",
    "df.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d6752",
   "metadata": {},
   "source": [
    "# Inspect class balance & basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46ed4041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 100\n",
      "label\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample grouped counts by question:\n",
      "label                        0   1\n",
      "question                          \n",
      "Cloud experience             4   4\n",
      "Data engineering skills      5   5\n",
      "DevOps experience            5   7\n",
      "Education background         6   6\n",
      "Machine learning experience  6   5\n",
      "Projects completed           5   3\n",
      "Publication list             4   4\n",
      "Python libraries             5  10\n",
      "Research interests           2   4\n",
      "Work experience              8   2\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nSample grouped counts by question:\")\n",
    "print(df.groupby('question')['label'].value_counts().unstack(fill_value=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461bf03",
   "metadata": {},
   "source": [
    "# Prepare features (concatenate question + chunk) and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de0ef9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 142)\n",
      "Sample feature names (first 20): ['2020' '2021' '2024' 'acme' 'actions' 'adaptation' 'advertising' 'ai'\n",
      " 'airflow' 'architectures' 'authored' 'automated' 'aws' 'background'\n",
      " 'blog' 'bsc' 'building' 'built' 'cafeteria' 'cd']\n"
     ]
    }
   ],
   "source": [
    "# Option: combine question and chunk as single text feature (improves classifier's ability to learn relevance)\n",
    "df['text'] = df['question'] + \" \" + df['chunk']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['text'])  # sparse matrix\n",
    "y = df['label'].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Sample feature names (first 20):\", vectorizer.get_feature_names_out()[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd179f6a",
   "metadata": {},
   "source": [
    "# Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be083d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 80\n",
      "Test samples: 20\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, df.index.values, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train samples:\", X_train.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffb42f",
   "metadata": {},
   "source": [
    "# Train classifier (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2ac45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b001f6f",
   "metadata": {},
   "source": [
    "# Evaluate on test set and print metrics + confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "496783a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1: 0.9\n",
      "\n",
      "Confusion matrix:\n",
      " [[9 1]\n",
      " [1 9]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "print(\"Precision:\", round(prec, 3))\n",
    "print(\"Recall:\", round(rec, 3))\n",
    "print(\"F1:\", round(f1, 3))\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8ddea",
   "metadata": {},
   "source": [
    "# Use the trained model to rank candidate chunks for a new question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c3e3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: prob=0.406, sim=0.111\n",
      "Chunk: Used numpy, pandas, sklearn...\n",
      "Source Question: Python libraries\n",
      "----\n",
      "Rank 2: prob=0.379, sim=0.054\n",
      "Chunk: He has 5 years of ML experience...\n",
      "Source Question: Machine learning experience\n",
      "----\n",
      "Rank 3: prob=0.319, sim=0.068\n",
      "Chunk: Company history overview...\n",
      "Source Question: Machine learning experience\n",
      "----\n",
      "Rank 4: prob=0.292, sim=0.022\n",
      "Chunk: Employee benefits details...\n",
      "Source Question: Python libraries\n",
      "----\n",
      "Rank 5: prob=0.281, sim=0.047\n",
      "Chunk: The office parking lot is empty.\n",
      "Source Question: Python libraries\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Candidate pool\n",
    "candidate_chunks = df['chunk'].tolist()\n",
    "candidate_files = df['question'].tolist()  # using question as doc id\n",
    "\n",
    "# Step 1: Encode chunks\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chunk_vectors = embed_model.encode(candidate_chunks, convert_to_numpy=True)\n",
    "\n",
    "# Step 2: Train a simple classifier on your labeled data\n",
    "# Assume df has columns: ['question', 'chunk', 'label']\n",
    "X_train = embed_model.encode(df['question'] + \" \" + df['chunk'], convert_to_numpy=True)\n",
    "y_train = df['label'].values\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Rank candidates for a new question\n",
    "def rank_candidates_for_question(question_text, top_k=5):\n",
    "    # Encode question + candidate chunks for classifier\n",
    "    query_vectors = embed_model.encode([question_text + \" \" + chunk for chunk in candidate_chunks], convert_to_numpy=True)\n",
    "    probs = clf.predict_proba(query_vectors)[:,1]\n",
    "\n",
    "    # Compute cosine similarity between question and chunks\n",
    "    q_vec = embed_model.encode([question_text], convert_to_numpy=True)\n",
    "    sims = cosine_similarity(q_vec, chunk_vectors).flatten()\n",
    "\n",
    "    # Rank by classifier probability, tie-breaker similarity\n",
    "    idxs = np.argsort(np.stack([probs, sims]).T[:,0])[::-1]\n",
    "    top = []\n",
    "    for i in idxs[:top_k]:\n",
    "        top.append({\n",
    "            \"chunk\": candidate_chunks[i],\n",
    "            \"source_question\": candidate_files[i],\n",
    "            \"prob\": float(probs[i]),\n",
    "            \"sim\": float(sims[i])\n",
    "        })\n",
    "    return top\n",
    "\n",
    "# Example usage\n",
    "question = \"Weather?\"\n",
    "top_results = rank_candidates_for_question(question, top_k=5)\n",
    "for i, r in enumerate(top_results, 1):\n",
    "    print(f\"Rank {i}: prob={r['prob']:.3f}, sim={r['sim']:.3f}\")\n",
    "    print(\"Chunk:\", r['chunk'])\n",
    "    print(\"Source Question:\", r['source_question'])\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35eb8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
